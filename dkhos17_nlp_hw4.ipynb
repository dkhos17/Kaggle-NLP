{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dkhos17-nlp-hw4.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyON/hVz2Ct69KhSE3nFfN8V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dkhos17/Kaggle-NLP/blob/main/dkhos17_nlp_hw4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKHVbAa4zpAH"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oteGYhoky8sV"
      },
      "source": [
        "QUESTION1, QUESTION2, IS_DUPLICATE = [\"How do I flow traffic to my website?\"], [\"How do I build traffic to my website?\"], [1]\r\n",
        "QUESTION1, QUESTION2, IS_DUPLICATE = [\"How do I flow traffic to my website?\"], [\"How do I build home near street?\"], [0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EVqh515yryc"
      },
      "source": [
        "MAX_QUESTION_LEN = 30\r\n",
        "\r\n",
        "def configure_data(data):\r\n",
        "    def config(q, dels=False):\r\n",
        "        q = q.replace(\"'s\", \" is\")\r\n",
        "        q = q.replace(\"'re\", \" are\")\r\n",
        "        q = q.replace(\"'m\", \" am\")\r\n",
        "        q = q.replace(\"'ll\", \" will\")\r\n",
        "        q = q.replace(\"'d\", \" would\")\r\n",
        "        q = q.replace(\"'t\", \" not\")\r\n",
        "        return ' '.join(q.split(' ')[:MAX_QUESTION_LEN])\r\n",
        "    \r\n",
        "    data['question1'] = data['question1'].apply(lambda q : config(q)) \r\n",
        "    data['question2'] = data['question2'].apply(lambda q : config(q))\r\n",
        "    return data\r\n",
        "\r\n",
        "my_data = pd.DataFrame(list(zip(QUESTION1, QUESTION2, IS_DUPLICATE)), columns =['question1', 'question2', 'is_duplicate'])\r\n",
        "my_data = configure_data(my_data)\r\n",
        "my_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkyUekRs1vjO"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtkSGgaD1iQq"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from transformers import BertModel, AdamW, BertTokenizer\r\n",
        "\r\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQAOriL017hc"
      },
      "source": [
        "class Dataset():\r\n",
        "    def __init__(self, questions, targets=None):\r\n",
        "        self.questions = questions\r\n",
        "        self.targets = targets\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.questions[0])\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        # [CLS] Q1 [SEP] Q2 [SEP] 0 0 0 ... LEN = (2*MAX_QUESTION_LEN+5)\r\n",
        "        ei = tokenizer(self.questions[0][index], self.questions[1][index], add_special_tokens=True, return_token_type_ids=True, \r\n",
        "                       return_attention_mask=True, padding='max_length', max_length = (2*MAX_QUESTION_LEN+5), truncation=True)\r\n",
        "        ita = (torch.LongTensor(ei['input_ids']), torch.LongTensor(ei['token_type_ids']), torch.LongTensor(ei['attention_mask']))\r\n",
        "        \r\n",
        "        return ita, self.targets[index] if self.targets else 0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VPvIcb12D4e"
      },
      "source": [
        "MyDataSet = Dataset([QUESTION1, QUESTION2], IS_DUPLICATE)\r\n",
        "MyDataLoader = DataLoader(MyDataSet, batch_size=len(IS_DUPLICATE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FhIIZyj4v4-"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRLshdO_4lXL"
      },
      "source": [
        "class BERT(nn.Module):\r\n",
        "    def __init__(self, drop=0.15, hdim=768):\r\n",
        "        super().__init__()\r\n",
        "        self.pretrained = BertModel.from_pretrained('bert-base-uncased')\r\n",
        "        self.dropout = nn.Dropout(drop)\r\n",
        "        self.linear = nn.Linear(hdim,1)\r\n",
        "\r\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\r\n",
        "        outputs = self.pretrained(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\r\n",
        "        outputs = self.dropout(outputs[1])\r\n",
        "        return self.linear(outputs)\r\n",
        "\r\n",
        "model = BERT().to(device)\r\n",
        "model.load_state_dict(torch.load('gdrive/My Drive/Colab Notebooks/MyBertModel'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te29aHs75K9Q"
      },
      "source": [
        "model.eval()\r\n",
        "PREDICTION = []\r\n",
        "with torch.no_grad():\r\n",
        "    for b, batch in enumerate(MyDataLoader):\r\n",
        "        # get current batch from data\r\n",
        "        Q_batch, _ = batch\r\n",
        "        Q_input_ids, Q_token_type_ids, Q_attention_mask= Q_batch\r\n",
        "        \r\n",
        "        # predict targets for current batch and learn by comparing it to real targets with loss func.\r\n",
        "        Q_pred = model(input_ids=Q_input_ids.to(device), token_type_ids=Q_token_type_ids.to(device), attention_mask=Q_attention_mask.to(device)).to(device)\r\n",
        "\r\n",
        "        # predict batch according to our trained model\r\n",
        "        PREDICTION = torch.sigmoid(Q_pred).cpu().numpy().squeeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5ZDvAo45mn6"
      },
      "source": [
        "# save data to submit\r\n",
        "result = pd.DataFrame({\"is_duplicate\": IS_DUPLICATE, \"my_prediction\" : PREDICTION})\r\n",
        "result.to_csv(\"result.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbaicpW25obh"
      },
      "source": [
        "result.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}